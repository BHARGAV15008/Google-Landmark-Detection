{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run webApp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define the directory containing the files you want to rename\n",
    "# directory = os.path.join(os.path.join(os.getcwd(), 'landmark_images'), 'train')\n",
    "# print(directory)\n",
    "# # Define the new extension you want to add\n",
    "# new_extension = \".jpg\"\n",
    "# listdirs = os.listdir(directory)\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for folder in listdirs:\n",
    "#     paths = os.path.join(directory, folder)\n",
    "#     fols = os.listdir(paths)\n",
    "#     print(fols)\n",
    "#     # Check if the item is a file (not a directory)\n",
    "#     for filename in fols:\n",
    "        \n",
    "#         new_filename = filename + new_extension\n",
    "        \n",
    "#         # Construct the full paths to the old and new files\n",
    "#         old_filepath = os.path.join(paths, filename)\n",
    "#         new_filepath = os.path.join(paths, new_filename)\n",
    "\n",
    "#         os.rename(old_filepath, new_filepath)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Download Datasets and Install Python Modules\n",
    "* [Step 1](#step1): Create a CNN to Classify Landmarks (from Scratch)\n",
    "* [Step 2](#step2): Create a CNN to Classify Landmarks (using Transfer Learning)\n",
    "* [Step 3](#step3): Write Your Landmark Prediction Algorithm\n",
    "* [step 4](#step4): Built GUI\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Download Datasets and Install Python Modules\n",
    "\n",
    "Install the following Python modules:\n",
    "* cv2\n",
    "* matplotlib\n",
    "* numpy\n",
    "* PIL\n",
    "* torch\n",
    "* torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python\n",
    "# %pip install matplotlib\n",
    "# %pip install numpy\n",
    "# %pip install PIL\n",
    "# %pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Create a CNN to Classify Landmarks (from Scratch)\n",
    "\n",
    "**In this experimental classification we have to try different Architecture.<br>**\n",
    "**Also we have to try some more Datsets.<br>**\n",
    "**Also different epochs.<br>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required dependency\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler \n",
    "# from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples the CNN sees and learn from at a time\n",
    "batch_size= 20 \n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data directories\n",
    "data_dir = 'landmark_images/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# transform data into specific format and fixed sized with the help of transform and normalize.\n",
    "data_transform = transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalize Data with using Standard deviation and mean\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
    "\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num test images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "indices = list(range(num_train)) # indices of the enire dataset\n",
    "\n",
    "np.random.shuffle(indices) # randomise indexes of dataset\n",
    "\n",
    "split = int(np.floor(valid_size * num_train))  # take 20% of training set size\n",
    "\n",
    "# set and define data loader for train Datasets and test Datasets\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=train_sampler, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=valid_sampler, num_workers=0)\n",
    "test_loader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow us to iterate data once batch at a time\n",
    "loaders_scratch = {'train':train_loader ,'valid': valid_loader, 'test':test_loader }\n",
    "\n",
    "\n",
    "#print(train_data.classes)\n",
    "classes = [classes_name.split(\".\")[1] for classes_name in train_data.classes]\n",
    "\n",
    "# for cls in classes:\n",
    "#     print(cls) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualize a Batch of Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "## TODO: visualize a batch of the train data loader\n",
    "## the class names can be accessed at the `classes` attribute\n",
    "## of your dataset object (e.g., `train_dataset.classes`)\n",
    "         \n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))  # convert from Tensor image\n",
    "    return img\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,2*8))\n",
    "for index in range(12):\n",
    "    ax = fig.add_subplot(4, 4, index+1, xticks=[], yticks=[])\n",
    "    rand_img = random.randint(0, len(train_data))\n",
    "    \n",
    "    img = imshow(train_data[rand_img][0]) # unnormalize\n",
    "    class_name = classes[train_data[rand_img][1]]\n",
    "    ax.set_title(class_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialize use_cuda variable**\n",
    "**If available then otherwise go for cpu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variable that tells us whether we should use the GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Specify Loss Function and Optimizer**\n",
    "\n",
    "**Finding Loss Function<br>**\n",
    "**Also set optimizer with learning rate 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "## TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer_scratch(model):\n",
    "    ## TODO: select and return an optimizer instead SGD use different optimizer\n",
    "    return optim.SGD(model.parameters(), lr=0.01)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Architecture**\n",
    "\n",
    "**Create a CNN to classify images of landmarks by using Use the Classes in the code cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "\n",
    "    ## TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32 , 256)\n",
    "        self.fc2 = nn.Linear(256, 50)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x = self.pool(F.relu(self.conv1(x))) # size 128\n",
    "        x = self.pool(F.relu(self.conv2(x))) # size 64\n",
    "        x = self.pool(F.relu(self.conv3(x))) # size 32\n",
    "        x = x.view(-1, 64 * 32 * 32 )\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "# # move tensors to GPU if CUDA is available\n",
    "# if use_cuda:\n",
    "#     model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implement the Training Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        # set the module to training mode\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda: # load them in parallel\n",
    "                data, target = data.cuda(), target.cuda() \n",
    "            \n",
    "            ## TODO: find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward() # calculate gradient\n",
    "            optimizer.step() # update wieghts\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data.item() - train_loss))\n",
    "\n",
    "\n",
    "        # set the model to evaluation mode\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            ## TODO: update average validation loss \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss =valid_loss + ((1 / (batch_idx + 1)) * (loss.data.item() - valid_loss))\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch,train_loss,valid_loss))\n",
    "\n",
    "        ## TODO: if the validation loss has decreased, save the model at the filepath stored in save_path\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment with the Weight Initialization**\n",
    "**Define Custome weight Initialization and try on few epochs.<br>Also make sure that validation and training loss is none**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_weight_init(m):\n",
    "    ## TODO: implement a weight initialization strategy\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    # for the two Linear layers\n",
    "    if classname.find('Linear') != -1:\n",
    "        num_inputs = m.in_features\n",
    "        \n",
    "        y= 1.0/np.sqrt(num_inputs) # general rule\n",
    "        m.weight.data.uniform_(-y , y) \n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**function to re-initialize a model with pytorch's default weight initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_weight_init(m):\n",
    "    reset_parameters = getattr(m, 'reset_parameters', None)\n",
    "    if callable(reset_parameters):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train and Validate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# function to re-initialize a model with pytorch's default weight initialization\n",
    "def default_weight_init(m):\n",
    "    reset_parameters = getattr(m, 'reset_parameters', None)\n",
    "    if callable(reset_parameters):\n",
    "        m.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_scratch.apply(custom_weight_init)\n",
    "# model_scratch = train(5, loaders_scratch, model_scratch, get_optimizer_scratch(model_scratch),\n",
    "#                       criterion_scratch, use_cuda, 'ignore.pt')x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_scratch.apply(default_weight_init) # reset the model parameters\n",
    "# model_scratch = train(num_epochs, loaders_scratch, model_scratch, get_optimizer_scratch(model_scratch), \n",
    "#                       criterion_scratch, use_cuda, 'model_scratch.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the Model**\n",
    "**Calculate and print the test loss and accuracy. <br>Ensure that your test accuracy is greater than 20%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    # set the module to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data.item() - test_loss))\n",
    "        \n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model for best validation\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Create a CNN to Classify Landmarks (using Transfer Learning)\n",
    "\n",
    "**We will now use transfer learning to create a CNN that can identify landmarks from images.  <br>Your CNN must attain at least 60% accuracy on the test set.**\n",
    "\n",
    "### **Specify Data Loaders for the Landmark Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "\n",
    "batch_size= 20 # how many samples the CNN sees and learn from at a time\n",
    "valid_size=0.2\n",
    "\n",
    "# allow us to iterate data once batch at a time\n",
    "loaders_transfer = loaders_scratch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data directories\n",
    "data_dir = 'landmark_images/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# transform data into specific format and fixed sized with the help of transform and normalize.\n",
    "data_transform = transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalize Data with using Standard deviation and mean\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
    "\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num test images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform datasets\n",
    "data_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_data)\n",
    "indices = list(range(num_train)) # indices of the enire dataset\n",
    "\n",
    "np.random.shuffle(indices) # randomise indexes of dataset\n",
    "\n",
    "split = int(np.floor(valid_size * num_train))  # take 20% of training set size\n",
    "\n",
    "# set and define data loader for train Datasets and test Datasets\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=train_sampler, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=valid_sampler, num_workers=0)\n",
    "test_loader =  torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow us to iterate data once batch at a time\n",
    "loaders_transfer = {'train':train_loader ,'valid': valid_loader, 'test':test_loader }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Specify Loss Function and Optimizer**\n",
    "\n",
    "**Finding Loss Function<br>**\n",
    "**Also set optimizer with learning rate 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: select loss function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer_transfer(model):\n",
    "    ## TODO: select and return optimizer\n",
    "    return optim.SGD(model.classifier.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Architecture**\n",
    "\n",
    "**Use transfer learning to create a CNN to classify images of landmarks.** **Also save our initialized model as the variable `model_transfer`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Specify model architecture\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "model_transfer = models.vgg16(pretrained=True)\n",
    "\n",
    "#freezing features- weights\n",
    "for param in model_transfer.features.parameters():\n",
    "    param.require_grad =False\n",
    "    \n",
    "# replace last layer    \n",
    "model_transfer.classifier[6] = nn.Linear( model_transfer.classifier[6].in_features , len(classes) )\n",
    "\n",
    "print(model_transfer)\n",
    "\n",
    "# if use_cuda:\n",
    "#     model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Since the VGG-16 model has been trained on millions of images, I used it as a pretrained model. We only need to replace the final fully connected layer of the model with our own problem to output 50 classes because we have a small dataset and similar data. Also, The parameters of all the feature layers of the model were also frozen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import signal\n",
    "\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "# import requests\n",
    "\n",
    "\n",
    "# DELAY = INTERVAL = 4 * 60  # interval time in seconds\n",
    "# MIN_DELAY = MIN_INTERVAL = 2 * 60\n",
    "# KEEPALIVE_URL = \"https://nebula.udacity.com/api/v1/remote/keep-alive\"\n",
    "# TOKEN_URL = \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\"\n",
    "# TOKEN_HEADERS = {\"Metadata-Flavor\":\"Google\"}\n",
    "\n",
    "\n",
    "# def _request_handler(headers):\n",
    "#     def _handler(signum, frame):\n",
    "#         requests.request(\"POST\", KEEPALIVE_URL, headers=headers)\n",
    "#     return _handler\n",
    "\n",
    "\n",
    "# @contextmanager\n",
    "# def active_session(delay=DELAY, interval=INTERVAL):\n",
    "#     \"\"\"\n",
    "#     Example:\n",
    "\n",
    "#     from workspace_utils import active session\n",
    "\n",
    "#     with active_session():\n",
    "#         # do long-running work here\n",
    "#     \"\"\"\n",
    "#     token = requests.request(\"GET\", TOKEN_URL, headers=TOKEN_HEADERS).text\n",
    "#     headers = {'Authorization': \"STAR \" + token}\n",
    "#     delay = max(delay, MIN_DELAY)\n",
    "#     interval = max(interval, MIN_INTERVAL)\n",
    "#     original_handler = signal.getsignal(signal.SIGALRM)\n",
    "#     try:\n",
    "#         signal.signal(signal.SIGALRM, _request_handler(headers))\n",
    "#         signal.setitimer(signal.ITIMER_REAL, delay, interval)\n",
    "#         yield\n",
    "#     finally:\n",
    "#         signal.signal(signal.SIGALRM, original_handler)\n",
    "#         signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "\n",
    "\n",
    "# def keep_awake(iterable, delay=DELAY, interval=INTERVAL):\n",
    "#     \"\"\"\n",
    "#     Example:\n",
    "\n",
    "#     from workspace_utils import keep_awake\n",
    "\n",
    "#     for i in keep_awake(range(5)):\n",
    "#         # do iteration with lots of work here\n",
    "#     \"\"\"\n",
    "#     with active_session(delay, interval): yield from iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train the model and save the best model parameters at filepath 'model_transfer.pt'\n",
    "num_epochs = 20\n",
    "\n",
    "# train the model\n",
    "model_transfer = train(num_epochs, loaders_transfer, model_transfer, get_optimizer_transfer(model_transfer), \n",
    "                      criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the Model**\n",
    "\n",
    "* **Try out your model on the test dataset of landmark images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Write Your Landmark Prediction Algorithm\n",
    "\n",
    "* **Great job creating your CNN models! Now that we have put in all the hard work of creating accurate classifiers.**\n",
    "\n",
    "### **Write Your Algorithm, Part 1**\n",
    "\n",
    "* **Implement the function `predict_landmarks`, which accepts a file path to an image and an integer k, and then predicts the *top k most likely landmarks*. You are *required* to use your transfer learned CNN from Step 2 to predict the landmarks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "## the class names can be accessed at the `classes` attribute\n",
    "## of your dataset object (e.g., `train_dataset.classes`)\n",
    "def predict_landmarks(img_path, k):\n",
    "    ## TODO: return the names of the top k landmarks predicted by the transfer learned CNN\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.ToTensor()])\n",
    "                                    \n",
    "    image= transform(image)\n",
    "    image.unsqueeze_(0)\n",
    "  \n",
    "    if use_cuda:\n",
    "        image = image.cuda()\n",
    "        \n",
    "    model_transfer.eval()  \n",
    "                                    \n",
    "    output = model_transfer(image)\n",
    "    values, indices = output.topk(k)\n",
    "    \n",
    "    top_k_classes = []\n",
    "    \n",
    "    for i in indices[0].tolist():\n",
    "        top_k_classes.append(classes[i])\n",
    "\n",
    "    model_transfer.train()\n",
    "    \n",
    "    return top_k_classes\n",
    "\n",
    "# test on a sample image\n",
    "print ( predict_landmarks('images/test/09.Golden_Gate_Bridge/190f3bae17c32c37.jpg', 5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write Your Algorithm, Part 2**\n",
    "\n",
    "**In the code cell below, implement the function `suggest_locations`, which accepts a file path to an image as input, and then displays the image and the *top 3 most likely landmarks* as predicted by `predict_landmarks`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def suggest_locations(img_path):\n",
    "    # get landmark predictions\n",
    "    predicted_landmarks = predict_landmarks(img_path, 3)\n",
    "    ## TODO: display image and display landmark predictions\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print('Is this picture of the',predicted_landmarks[0],',', predicted_landmarks[1],', or', predicted_landmarks[2])\n",
    "    \n",
    "    return f'This is the {predicted_landmarks}'\n",
    "# test on a sample image\n",
    "suggest_locations('images/test/09.Golden_Gate_Bridge/190f3bae17c32c37.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Your Algorithm**\n",
    "\n",
    "**Test algorithm by running the `suggest_locations` function on at least four images on your computer. Feel free to use any images you like.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TODO: Execute the `suggest_locations` function on\n",
    "# ## at least 4 images on your computer.\n",
    "# ## Feel free to use as many code cells as needed.\n",
    "\n",
    "# suggest_locations('myimages/pic1.jpg')\n",
    "\n",
    "\n",
    "# suggest_locations('myimages/pic2.jpg')\n",
    "\n",
    "# suggest_locations('myimages/pic3.jpg')\n",
    "\n",
    "# suggest_locations('myimages/pic4.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Three possible points for improvement)<br>**\n",
    "**In general, the outputs are better than what I expected.<br>**\n",
    "**Possible points for improvement:-<br>**\n",
    "    **1. More related training data should be fed into the model.<br>**\n",
    "    **2. Trying some changes in the model architecture, like adding more fully connected layers<br>**\n",
    "    **3. Trying other hyperparameter values<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
